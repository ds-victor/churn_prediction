# ğŸ“‰ Customer Churn Prediction using Machine Learning

Churn Prediction project that identifies customers who are likely to discontinue a service.
The model is trained using classical machine learning algorithms and deployed as an interactive Streamlit web application.

ğŸ”— Live App:
ğŸ‘‰ https://churnprediction-afe4bt8gfrljqjvribprqy.streamlit.app/

## ğŸ“Œ Problem Statement
Customer churn is a critical issue for subscription-based businesses.
Predicting churn in advance allows organizations to:
- Retain high-value customers
- Reduce revenue loss
- Design targeted retention strategies

This project predicts whether a customer is likely to Churn or Not Churn based on historical customer data.

## ğŸš€ Key Features
- End-to-end ML pipeline
- Data cleaning & exploratory analysis using Jupyter
- Feature engineering & preprocessing
- Multiple ML models trained and compared
- Best-performing model selected for deployment
- Streamlit-based UI for real-time predictions
- Production-ready project structure

## ğŸŒ Live Application
ğŸ”— Try the app here:
ğŸ‘‰ https://churnprediction-afe4bt8gfrljqjvribprqy.streamlit.app/

### App Capabilities
- Enter customer details
- Predict Churn / No Churn
- Fast, real-time inference

## ğŸ§  Machine Learning Workflow
```
Raw Customer Data
   â†“
Data Cleaning & Feature Engineering
   â†“
Exploratory Data Analysis (EDA)
   â†“
Model Training & Evaluation
   â†“
Best Model Selection
   â†“
Streamlit Deployment
```

## ğŸ“ Project Structure
```
customer_churn/
â”‚
â”œâ”€â”€ app.py                          # Streamlit entry point (ROOT)
â”œâ”€â”€ requirements.txt                # Dependencies (ROOT)
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ src/                            # Core ML logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                   # Paths, constants
â”‚   â”œâ”€â”€ preprocessing.py            # Data preprocessing logic
â”‚   â”œâ”€â”€ training.py                 # Model training pipeline
â”‚   â””â”€â”€ deployment.py               # Model loading & prediction service
â”‚
â”œâ”€â”€ data/                           # Data files
â”‚   â”œâ”€â”€ Telco_Customer_Churn.csv    # Raw dataset
â”‚   â””â”€â”€ cleaned_data.csv            # Cleaned dataset (from notebook)
â”‚
â”œâ”€â”€ notebooks/                      # Analysis & experimentation
â”‚   â”œâ”€â”€ data_cleaning.ipynb
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ models/                         # Trained models & artifacts
â”‚   â”œâ”€â”€ best_model.joblib
â”‚   â”œâ”€â”€ gradient_boosting_best_model.joblib
â”‚   â”œâ”€â”€ log_reg_best_model.joblib
â”‚   â”œâ”€â”€ random_forest_best_model.joblib
â”‚   â”œâ”€â”€ svc_best_model.joblib
â”‚   â””â”€â”€ feature_columns.json
â”‚
â””â”€â”€ venv/                           # Virtual environment (ignored)


```
## ğŸ“Š Dataset
- Telco_Customer_Churn.csv â€“ Raw customer churn dataset
- cleaned_data.csv â€“ Cleaned dataset created using Jupyter Notebook

The dataset contains:
  - Demographic information
  - Account details
  - Service usage metrics

## âš™ï¸ Installation & Setup
### 1ï¸âƒ£ Clone the repository
  git clone https://github.com/yourusername/customer_churn.git
  cd customer_churn
  
  ### 2ï¸âƒ£ Create and activate a virtual environment
  - python -m venv venv
  - venv\Scripts\activate      # Windows
  - source venv/bin/activate   # macOS/Linux
  
### 3ï¸âƒ£ Install dependencies
  - pip install -r requirements.txt

## ğŸ§¹ Data Preparation
- Data cleaning and EDA are performed in:
    - notebooks/data_cleaning.ipynb
    - notebooks/eda.ipynb
- After cleaning, export the processed dataset to:
    - data/cleaned_data.csv
  The training pipeline expects this file to exist

## ğŸ¤– Model Training
Run training from the project root:
   - python -m src.training
Training will:
  - Load cleaned data
  - Create train/test splits (stratified)
  - Build preprocessing pipeline
  - Train multiple ML models using GridSearchCV
  - Save:
    - models/best_model.joblib
    - models/<model>_best_model.joblib
    - models/feature_columns.json
  
  The saved model and feature file ensure consistent prediction during deployment.

## ğŸ–¥ï¸ Run Streamlit App
From the project root:
   - streamlit run src/app.py

## Features:
  - Single-customer prediction
  - Batch predictions via CSV upload
  - Automatic feature alignment
  - Probability output
  - Clean UI with error handling
  
## ğŸ“¦ Deployment & Prediction API
### Deployment:
   - src/deployment.py

### Prediction:
  - predict_single(input_dict)   # returns dict with prediction + probability
  - predict_batch(dataframe)     # returns dataframe with predictions appended
  - The functions: (Align input to training features)
    - Coerce numeric types
    - Handle missing columns gracefully
    - Ensure stable predictions

## ğŸ“Š Technologies Used
- Python 3.10+
- Pandas, NumPy
- Scikit-Learn
- Joblib
- Streamlit
- Jupyter Notebook

## ğŸš€ Future Enhancements
- SHAP explainability
- FastAPI REST API
- Docker deployment
- Monitoring & model drift detection
- Optuna Bayesian optimization

## ğŸ¤ Contributing
- Contributions, suggestions, and feature requests are welcome.
- Feel free to open an issue or submit a pull request.

## ğŸ™ Acknowledgements
- Inspired by public telecom churn datasets.
- Thanks to the open-source community for their amazing tools.

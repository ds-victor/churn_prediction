# ğŸ“Š Customer Churn Prediction
A complete end-to-end machine learning pipeline with preprocessing, model selection, and Streamlit deployment.

## ğŸŒŸ Project Overview
This project implements a full Telecom Customer Churn Prediction System using:
- Python
- Scikit-Learn Pipelines
- Feature Engineering (Imputation, Scaling, One-Hot Encoding)
- GridSearchCV Hyperparameter Tuning
- Streamlit Web Application
- Modular, well-structured folder

The workflow trains multiple ML models, selects the best one, and serves predictions in a user-friendly web interface.

## ğŸ“ Project Structure
```
customer_churn/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ cleaned_data.csv
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.joblib
â”‚   â”œâ”€â”€ feature_columns.json
â”‚   â””â”€â”€ <model>_best_model.joblib
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ cleaning.ipynb
â”‚   â””â”€â”€ eda.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ training.py
â”‚   â”œâ”€â”€ deployment.py
â”‚   â””â”€â”€ app.py
â”‚
â””â”€â”€ README.md

```
## âš™ï¸ Installation & Setup
### 1ï¸âƒ£ Clone the repository
  git clone https://github.com/yourusername/customer_churn.git
  cd customer_churn
### 2ï¸âƒ£ Create and activate a virtual environment
  - python -m venv venv
  - venv\Scripts\activate      # Windows
  - source venv/bin/activate   # macOS/Linux
### 3ï¸âƒ£ Install dependencies
  - pip install -r requirements.txt

## ğŸ§¹ Data Preparation
- Data cleaning and EDA are performed in:
    - notebooks/data_cleaning.ipynb
    - notebooks/eda.ipynb
- After cleaning, export the processed dataset to:
    - data/cleaned_data.csv
  The training pipeline expects this file to exist

## ğŸ¤– Model Training
Run training from the project root:
- python -m src.training
- Training will:
    - Load cleaned data
    - Create train/test splits (stratified)
    - Build preprocessing pipeline
    - Train multiple ML models using GridSearchCV
- Save:
    - models/best_model.joblib
    - models/<model>_best_model.joblib
    - models/feature_columns.json
  
  The saved model and feature file ensure consistent prediction during deployment.

## ğŸ–¥ï¸ Run Streamlit App
From the project root:
- streamlit run src/app.py
- Features:
    - Single-customer prediction
    - Batch predictions via CSV upload
    - Automatic feature alignment
    - Probability output
    - Clean UI with error handling
  
## ğŸ“¦ Deployment & Prediction API
- src/deployment.py provides:
  - predict_single(input_dict)   # returns dict with prediction + probability
  - predict_batch(dataframe)     # returns dataframe with predictions appended
- The functions: (Align input to training features)
    - Coerce numeric types
    - Handle missing columns gracefully
    - Ensure stable predictions

## ğŸ“Š Technologies Used
- Python 3.10+
- Pandas, NumPy
- Scikit-Learn
- Joblib
- Streamlit
- Jupyter Notebook

## ğŸš€ Future Enhancements
- SHAP explainability
- FastAPI REST API
- Docker deployment
- Monitoring & model drift detection
- Optuna Bayesian optimization

## ğŸ¤ Contributing
- Contributions, suggestions, and feature requests are welcome.
- Feel free to open an issue or submit a pull request.

## ğŸ™ Acknowledgements
- Inspired by public telecom churn datasets.
- Thanks to the open-source community for their amazing tools.
